{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'ntc-scv'...\n",
      "Updating files:  72% (8/11)\n",
      "Updating files:  81% (9/11)\n",
      "Updating files:  90% (10/11)\n",
      "Updating files: 100% (11/11)\n",
      "Updating files: 100% (11/11), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/congnghia0609/ntc-scv.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: ./data/ntc-scv\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "train_path = \"./ntc-scv/data/data_train.zip\"\n",
    "test_path = \"./ntc-scv/data/data_test.zip\"\n",
    "extract_path = \"./data/ntc-scv\"\n",
    "\n",
    "\n",
    "\n",
    "# Ensure the extraction folder exists\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Unzipping the file\n",
    "with zipfile.ZipFile(train_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "with zipfile.ZipFile(test_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(f\"Files extracted to: {extract_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_path(folder_path):\n",
    "    examples = []\n",
    "    for label in os.listdir(folder_path):\n",
    "        full_path = os.path.join(folder_path, label)\n",
    "        for file_name in os.listdir(full_path):\n",
    "            file_path = os.path.join(full_path, file_name)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                lines = f.readlines()\n",
    "            sentence = \" \".join(lines)\n",
    "            if label == \"neg\":\n",
    "                label = 0\n",
    "            if label == \"pos\":\n",
    "                label = 1\n",
    "            data = {\n",
    "                'sentence': sentence,\n",
    "                'label': label\n",
    "            }\n",
    "            examples.append(data)\n",
    "    return pd.DataFrame(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = {\n",
    "    'train': './data/ntc-scv/data_train/train',\n",
    "    'valid': './data/ntc-scv/data_train/test',\n",
    "    'test': './data/ntc-scv/data_test/test'\n",
    "}\n",
    "\n",
    "train_df = load_data_from_path(folder_paths['train'])\n",
    "valid_df = load_data_from_path(folder_paths['valid'])\n",
    "test_df = load_data_from_path(folder_paths['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langid\n",
      "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     ---------- ----------------------------- 0.5/1.9 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.9/1.9 MB 7.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\envs\\aio_exercise\\lib\\site-packages (from langid) (2.1.3)\n",
      "Building wheels for collected packages: langid\n",
      "  Building wheel for langid (setup.py): started\n",
      "  Building wheel for langid (setup.py): finished with status 'done'\n",
      "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941178 sha256=fee57c8f6255e37447dcb71fcff00808d979404654eb44de613fee7c6b871f57\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\23\\c8\\c6\\eed80894918490a175677414d40bd7c851413bbe03d4856c3c\n",
      "Successfully built langid\n",
      "Installing collected packages: langid\n",
      "Successfully installed langid-1.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langid.langid import LanguageIdentifier, model\n",
    "\n",
    "\n",
    "def identify_vn(df):\n",
    "    identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
    "    not_vi_idx = set()\n",
    "    THRESHOLD = 0.9\n",
    "    for idx, row in df.iterrows():\n",
    "        score = identifier.classify(row[\"sentence\"])\n",
    "        if score[0] != \"vi\" or (score[0] == \"vi\" and score[1] <= THRESHOLD):\n",
    "            not_vi_idx.add(idx)\n",
    "    vi_df = df[~df.index.isin(not_vi_idx)]\n",
    "    not_vi_df = df[df.index.isin(not_vi_idx)]\n",
    "    return vi_df, not_vi_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio_exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
