{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qiUDDoYyRLBiKOoYWdFl_5WByHE8Cugu\n",
      "To: c:\\Users\\ADMIN\\OneDrive - VNU-HCMUS\\Old Laptop\\AIO2024\\Main Class\\AIO-Exercise\\Module_5\\Week_3\\Auto_MPG_data.csv\n",
      "\n",
      "  0%|          | 0.00/15.4k [00:00<?, ?B/s]\n",
      "100%|██████████| 15.4k/15.4k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "!gdown 1qiUDDoYyRLBiKOoYWdFl_5WByHE8Cugu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random seed\n",
    "random_state = 59\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './Auto_MPG_data.csv'\n",
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns='MPG').to_numpy()\n",
    "y = dataset['MPG'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "is_shuffle = True\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size = val_size,\n",
    "    random_state = random_state,\n",
    "    shuffle = is_shuffle\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size = test_size,\n",
    "    random_state = random_state,\n",
    "    shuffle = is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_val = normalizer.transform(X_val)\n",
    "X_test = normalizer.transform(X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype = torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype = torch.float32) \n",
    "y_test = torch.tensor(y_test, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pytorch dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataloader\n",
    "batch_size = 32\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle= True)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_pred):\n",
    "    y_true = torch.Tensor(y_true).to(device)\n",
    "    y_pred = torch.Tensor(y_pred).to(device)\n",
    "    mean_true = torch.mean(y_true)\n",
    "    ss_res = torch.sum((y_true - y_pred)**2)\n",
    "    ss_tot = torch.sum((y_true - mean_true)**2)\n",
    "    r2 = 1 - ss_res/ss_tot\n",
    "    return r2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, epochs, optimizer, criterion):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_r2 = []\n",
    "    val_r2 = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        train_target = []\n",
    "        train_predict = []\n",
    "        val_target = []\n",
    "        val_predict = []\n",
    "        model.train() # start train\n",
    "        for X_samples, y_samples in train_loader:\n",
    "            X_samples = X_samples.to(device)\n",
    "            y_samples = y_samples.to(device)\n",
    "            optimizer.zero_grad() # reset grad\n",
    "            outputs = model(X_samples)\n",
    "            train_predict += outputs.tolist()\n",
    "            train_target += y_samples.tolist()\n",
    "            loss = criterion(outputs, y_samples)\n",
    "            loss.backward()\n",
    "            optimizer.step() # update para\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_r2.append(r_squared(train_target, train_predict))\n",
    "        model.eval() # set model to evaluation\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_samples, y_samples in val_loader:\n",
    "                X_samples = X_samples.to(device)\n",
    "                y_samples = y_samples.to(device)\n",
    "                outputs = model(X_samples)\n",
    "                val_predict += outputs.tolist()\n",
    "                val_target += y_samples.tolist()\n",
    "                loss = criterion(outputs, y_samples)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        val_r2.append(r_squared(val_target, val_predict))\n",
    "        print(f'\\nEPOCH {epoch + 1}:\\tTraining loss: {train_loss: .3f}\\tValidation loss: {val_loss: .3f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(X_test)\n",
    "        test_set_r2 = r_squared(y_hat, y_test)\n",
    "        print('valuation on test set:')\n",
    "        print(f'R2: {test_set_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims, activation):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dims, hidden_dims)\n",
    "        self.linear2 = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.output = nn.Linear(hidden_dims, output_dims)\n",
    "        self.activation = activation\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        activations = {\n",
    "            'relu': F.relu,\n",
    "            'sigmoid': torch.sigmoid,\n",
    "            'tanh': torch.tanh\n",
    "        }\n",
    "        x = activations[self.activation](x)\n",
    "        x = self.linear2(x)\n",
    "        x = activations[self.activation](x)\n",
    "        out = self.output(x)\n",
    "        return out.squeeze(1)\n",
    "    \n",
    "input_dims = X_train.shape[1]\n",
    "output_dims = 1\n",
    "hidden_dims = 64\n",
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1:\tTraining loss:  282.770\tValidation loss:  88.669\n",
      "\n",
      "EPOCH 2:\tTraining loss:  137.601\tValidation loss:  72.725\n",
      "\n",
      "EPOCH 3:\tTraining loss:  73.024\tValidation loss:  23.437\n",
      "\n",
      "EPOCH 4:\tTraining loss:  33.473\tValidation loss:  9.792\n",
      "\n",
      "EPOCH 5:\tTraining loss:  15.966\tValidation loss:  21.951\n",
      "\n",
      "EPOCH 6:\tTraining loss:  40.587\tValidation loss:  26.677\n",
      "\n",
      "EPOCH 7:\tTraining loss:  21.031\tValidation loss:  5.269\n",
      "\n",
      "EPOCH 8:\tTraining loss:  40.389\tValidation loss:  96.423\n",
      "\n",
      "EPOCH 9:\tTraining loss:  26.096\tValidation loss:  43.621\n",
      "\n",
      "EPOCH 10:\tTraining loss:  29.136\tValidation loss:  45.975\n",
      "\n",
      "EPOCH 11:\tTraining loss:  32.704\tValidation loss:  26.076\n",
      "\n",
      "EPOCH 12:\tTraining loss:  10.828\tValidation loss:  5.663\n",
      "\n",
      "EPOCH 13:\tTraining loss:  15.924\tValidation loss:  20.072\n",
      "\n",
      "EPOCH 14:\tTraining loss:  13.710\tValidation loss:  16.768\n",
      "\n",
      "EPOCH 15:\tTraining loss:  17.010\tValidation loss:  9.460\n",
      "\n",
      "EPOCH 16:\tTraining loss:  11.250\tValidation loss:  22.420\n",
      "\n",
      "EPOCH 17:\tTraining loss:  14.216\tValidation loss:  13.509\n",
      "\n",
      "EPOCH 18:\tTraining loss:  16.240\tValidation loss:  12.670\n",
      "\n",
      "EPOCH 19:\tTraining loss:  15.375\tValidation loss:  5.766\n",
      "\n",
      "EPOCH 20:\tTraining loss:  7.527\tValidation loss:  5.076\n",
      "\n",
      "EPOCH 21:\tTraining loss:  8.800\tValidation loss:  4.754\n",
      "\n",
      "EPOCH 22:\tTraining loss:  6.380\tValidation loss:  5.175\n",
      "\n",
      "EPOCH 23:\tTraining loss:  10.710\tValidation loss:  59.299\n",
      "\n",
      "EPOCH 24:\tTraining loss:  12.424\tValidation loss:  16.927\n",
      "\n",
      "EPOCH 25:\tTraining loss:  9.916\tValidation loss:  8.804\n",
      "\n",
      "EPOCH 26:\tTraining loss:  11.849\tValidation loss:  6.475\n",
      "\n",
      "EPOCH 27:\tTraining loss:  6.550\tValidation loss:  6.742\n",
      "\n",
      "EPOCH 28:\tTraining loss:  11.106\tValidation loss:  5.074\n",
      "\n",
      "EPOCH 29:\tTraining loss:  7.001\tValidation loss:  12.686\n",
      "\n",
      "EPOCH 30:\tTraining loss:  20.182\tValidation loss:  5.033\n",
      "\n",
      "EPOCH 31:\tTraining loss:  8.578\tValidation loss:  6.809\n",
      "\n",
      "EPOCH 32:\tTraining loss:  7.518\tValidation loss:  6.221\n",
      "\n",
      "EPOCH 33:\tTraining loss:  7.952\tValidation loss:  4.634\n",
      "\n",
      "EPOCH 34:\tTraining loss:  7.263\tValidation loss:  6.527\n",
      "\n",
      "EPOCH 35:\tTraining loss:  7.948\tValidation loss:  6.521\n",
      "\n",
      "EPOCH 36:\tTraining loss:  6.240\tValidation loss:  7.029\n",
      "\n",
      "EPOCH 37:\tTraining loss:  6.758\tValidation loss:  6.337\n",
      "\n",
      "EPOCH 38:\tTraining loss:  7.507\tValidation loss:  10.383\n",
      "\n",
      "EPOCH 39:\tTraining loss:  7.896\tValidation loss:  16.522\n",
      "\n",
      "EPOCH 40:\tTraining loss:  8.283\tValidation loss:  6.185\n",
      "\n",
      "EPOCH 41:\tTraining loss:  6.413\tValidation loss:  27.816\n",
      "\n",
      "EPOCH 42:\tTraining loss:  10.057\tValidation loss:  5.757\n",
      "\n",
      "EPOCH 43:\tTraining loss:  7.297\tValidation loss:  29.445\n",
      "\n",
      "EPOCH 44:\tTraining loss:  10.810\tValidation loss:  12.811\n",
      "\n",
      "EPOCH 45:\tTraining loss:  6.900\tValidation loss:  5.067\n",
      "\n",
      "EPOCH 46:\tTraining loss:  8.863\tValidation loss:  7.692\n",
      "\n",
      "EPOCH 47:\tTraining loss:  6.807\tValidation loss:  6.257\n",
      "\n",
      "EPOCH 48:\tTraining loss:  5.715\tValidation loss:  6.494\n",
      "\n",
      "EPOCH 49:\tTraining loss:  6.767\tValidation loss:  11.664\n",
      "\n",
      "EPOCH 50:\tTraining loss:  7.492\tValidation loss:  16.142\n",
      "\n",
      "EPOCH 51:\tTraining loss:  8.944\tValidation loss:  8.873\n",
      "\n",
      "EPOCH 52:\tTraining loss:  12.770\tValidation loss:  5.000\n",
      "\n",
      "EPOCH 53:\tTraining loss:  8.194\tValidation loss:  5.161\n",
      "\n",
      "EPOCH 54:\tTraining loss:  6.953\tValidation loss:  5.505\n",
      "\n",
      "EPOCH 55:\tTraining loss:  5.706\tValidation loss:  5.162\n",
      "\n",
      "EPOCH 56:\tTraining loss:  5.841\tValidation loss:  5.970\n",
      "\n",
      "EPOCH 57:\tTraining loss:  8.095\tValidation loss:  7.667\n",
      "\n",
      "EPOCH 58:\tTraining loss:  7.566\tValidation loss:  19.179\n",
      "\n",
      "EPOCH 59:\tTraining loss:  7.842\tValidation loss:  8.039\n",
      "\n",
      "EPOCH 60:\tTraining loss:  6.143\tValidation loss:  4.804\n",
      "\n",
      "EPOCH 61:\tTraining loss:  6.143\tValidation loss:  9.030\n",
      "\n",
      "EPOCH 62:\tTraining loss:  11.451\tValidation loss:  4.862\n",
      "\n",
      "EPOCH 63:\tTraining loss:  7.004\tValidation loss:  14.823\n",
      "\n",
      "EPOCH 64:\tTraining loss:  6.229\tValidation loss:  5.471\n",
      "\n",
      "EPOCH 65:\tTraining loss:  8.879\tValidation loss:  5.406\n",
      "\n",
      "EPOCH 66:\tTraining loss:  5.585\tValidation loss:  5.240\n",
      "\n",
      "EPOCH 67:\tTraining loss:  7.176\tValidation loss:  7.906\n",
      "\n",
      "EPOCH 68:\tTraining loss:  10.634\tValidation loss:  6.749\n",
      "\n",
      "EPOCH 69:\tTraining loss:  7.571\tValidation loss:  8.011\n",
      "\n",
      "EPOCH 70:\tTraining loss:  6.131\tValidation loss:  5.448\n",
      "\n",
      "EPOCH 71:\tTraining loss:  5.627\tValidation loss:  4.862\n",
      "\n",
      "EPOCH 72:\tTraining loss:  6.308\tValidation loss:  9.090\n",
      "\n",
      "EPOCH 73:\tTraining loss:  6.732\tValidation loss:  9.356\n",
      "\n",
      "EPOCH 74:\tTraining loss:  6.344\tValidation loss:  5.630\n",
      "\n",
      "EPOCH 75:\tTraining loss:  5.788\tValidation loss:  18.185\n",
      "\n",
      "EPOCH 76:\tTraining loss:  8.070\tValidation loss:  19.024\n",
      "\n",
      "EPOCH 77:\tTraining loss:  12.289\tValidation loss:  6.846\n",
      "\n",
      "EPOCH 78:\tTraining loss:  6.836\tValidation loss:  5.272\n",
      "\n",
      "EPOCH 79:\tTraining loss:  5.964\tValidation loss:  8.927\n",
      "\n",
      "EPOCH 80:\tTraining loss:  8.242\tValidation loss:  5.507\n",
      "\n",
      "EPOCH 81:\tTraining loss:  12.211\tValidation loss:  6.752\n",
      "\n",
      "EPOCH 82:\tTraining loss:  6.014\tValidation loss:  5.639\n",
      "\n",
      "EPOCH 83:\tTraining loss:  6.231\tValidation loss:  7.995\n",
      "\n",
      "EPOCH 84:\tTraining loss:  5.736\tValidation loss:  5.310\n",
      "\n",
      "EPOCH 85:\tTraining loss:  5.321\tValidation loss:  5.811\n",
      "\n",
      "EPOCH 86:\tTraining loss:  4.954\tValidation loss:  6.272\n",
      "\n",
      "EPOCH 87:\tTraining loss:  5.307\tValidation loss:  8.060\n",
      "\n",
      "EPOCH 88:\tTraining loss:  5.566\tValidation loss:  5.444\n",
      "\n",
      "EPOCH 89:\tTraining loss:  4.978\tValidation loss:  5.777\n",
      "\n",
      "EPOCH 90:\tTraining loss:  7.706\tValidation loss:  6.275\n",
      "\n",
      "EPOCH 91:\tTraining loss:  5.938\tValidation loss:  9.405\n",
      "\n",
      "EPOCH 92:\tTraining loss:  7.700\tValidation loss:  5.600\n",
      "\n",
      "EPOCH 93:\tTraining loss:  6.158\tValidation loss:  5.466\n",
      "\n",
      "EPOCH 94:\tTraining loss:  9.238\tValidation loss:  7.235\n",
      "\n",
      "EPOCH 95:\tTraining loss:  6.695\tValidation loss:  6.524\n",
      "\n",
      "EPOCH 96:\tTraining loss:  9.059\tValidation loss:  22.104\n",
      "\n",
      "EPOCH 97:\tTraining loss:  7.563\tValidation loss:  12.059\n",
      "\n",
      "EPOCH 98:\tTraining loss:  7.775\tValidation loss:  8.262\n",
      "\n",
      "EPOCH 99:\tTraining loss:  6.988\tValidation loss:  6.461\n",
      "\n",
      "EPOCH 100:\tTraining loss:  6.795\tValidation loss:  5.282\n",
      "valuation on test set:\n",
      "R2: 0.8332918882369995\n"
     ]
    }
   ],
   "source": [
    "model = MLP(input_dims, hidden_dims, output_dims, activation='relu').to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "train_and_evaluate(model, epochs=100, optimizer=optimizer, criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1:\tTraining loss:  394.539\tValidation loss:  165.868\n",
      "\n",
      "EPOCH 2:\tTraining loss:  48.157\tValidation loss:  42.470\n",
      "\n",
      "EPOCH 3:\tTraining loss:  58.916\tValidation loss:  37.810\n",
      "\n",
      "EPOCH 4:\tTraining loss:  27.355\tValidation loss:  7.610\n",
      "\n",
      "EPOCH 5:\tTraining loss:  15.265\tValidation loss:  16.799\n",
      "\n",
      "EPOCH 6:\tTraining loss:  16.935\tValidation loss:  10.642\n",
      "\n",
      "EPOCH 7:\tTraining loss:  12.903\tValidation loss:  8.280\n",
      "\n",
      "EPOCH 8:\tTraining loss:  12.169\tValidation loss:  8.075\n",
      "\n",
      "EPOCH 9:\tTraining loss:  12.138\tValidation loss:  8.364\n",
      "\n",
      "EPOCH 10:\tTraining loss:  12.528\tValidation loss:  8.572\n",
      "\n",
      "EPOCH 11:\tTraining loss:  12.215\tValidation loss:  8.489\n",
      "\n",
      "EPOCH 12:\tTraining loss:  11.814\tValidation loss:  8.409\n",
      "\n",
      "EPOCH 13:\tTraining loss:  11.754\tValidation loss:  8.341\n",
      "\n",
      "EPOCH 14:\tTraining loss:  12.359\tValidation loss:  7.954\n",
      "\n",
      "EPOCH 15:\tTraining loss:  11.837\tValidation loss:  8.401\n",
      "\n",
      "EPOCH 16:\tTraining loss:  12.241\tValidation loss:  7.981\n",
      "\n",
      "EPOCH 17:\tTraining loss:  12.327\tValidation loss:  8.685\n",
      "\n",
      "EPOCH 18:\tTraining loss:  12.110\tValidation loss:  7.881\n",
      "\n",
      "EPOCH 19:\tTraining loss:  11.980\tValidation loss:  8.129\n",
      "\n",
      "EPOCH 20:\tTraining loss:  11.705\tValidation loss:  7.750\n",
      "\n",
      "EPOCH 21:\tTraining loss:  11.593\tValidation loss:  7.934\n",
      "\n",
      "EPOCH 22:\tTraining loss:  11.489\tValidation loss:  8.055\n",
      "\n",
      "EPOCH 23:\tTraining loss:  11.714\tValidation loss:  7.563\n",
      "\n",
      "EPOCH 24:\tTraining loss:  11.707\tValidation loss:  7.891\n",
      "\n",
      "EPOCH 25:\tTraining loss:  11.616\tValidation loss:  7.982\n",
      "\n",
      "EPOCH 26:\tTraining loss:  11.701\tValidation loss:  7.533\n",
      "\n",
      "EPOCH 27:\tTraining loss:  11.963\tValidation loss:  8.149\n",
      "\n",
      "EPOCH 28:\tTraining loss:  12.055\tValidation loss:  7.714\n",
      "\n",
      "EPOCH 29:\tTraining loss:  11.850\tValidation loss:  7.623\n",
      "\n",
      "EPOCH 30:\tTraining loss:  12.330\tValidation loss:  7.698\n",
      "\n",
      "EPOCH 31:\tTraining loss:  12.341\tValidation loss:  7.742\n",
      "\n",
      "EPOCH 32:\tTraining loss:  11.815\tValidation loss:  7.764\n",
      "\n",
      "EPOCH 33:\tTraining loss:  11.638\tValidation loss:  7.693\n",
      "\n",
      "EPOCH 34:\tTraining loss:  11.359\tValidation loss:  7.759\n",
      "\n",
      "EPOCH 35:\tTraining loss:  11.786\tValidation loss:  7.853\n",
      "\n",
      "EPOCH 36:\tTraining loss:  11.663\tValidation loss:  7.414\n",
      "\n",
      "EPOCH 37:\tTraining loss:  11.511\tValidation loss:  7.730\n",
      "\n",
      "EPOCH 38:\tTraining loss:  11.636\tValidation loss:  7.877\n",
      "\n",
      "EPOCH 39:\tTraining loss:  11.332\tValidation loss:  7.420\n",
      "\n",
      "EPOCH 40:\tTraining loss:  11.689\tValidation loss:  7.569\n",
      "\n",
      "EPOCH 41:\tTraining loss:  12.102\tValidation loss:  7.879\n",
      "\n",
      "EPOCH 42:\tTraining loss:  12.153\tValidation loss:  7.570\n",
      "\n",
      "EPOCH 43:\tTraining loss:  11.626\tValidation loss:  7.560\n",
      "\n",
      "EPOCH 44:\tTraining loss:  11.457\tValidation loss:  7.807\n",
      "\n",
      "EPOCH 45:\tTraining loss:  11.913\tValidation loss:  7.472\n",
      "\n",
      "EPOCH 46:\tTraining loss:  11.461\tValidation loss:  7.785\n",
      "\n",
      "EPOCH 47:\tTraining loss:  11.634\tValidation loss:  7.538\n",
      "\n",
      "EPOCH 48:\tTraining loss:  11.998\tValidation loss:  7.541\n",
      "\n",
      "EPOCH 49:\tTraining loss:  12.052\tValidation loss:  7.891\n",
      "\n",
      "EPOCH 50:\tTraining loss:  11.730\tValidation loss:  8.010\n",
      "\n",
      "EPOCH 51:\tTraining loss:  12.246\tValidation loss:  7.468\n",
      "\n",
      "EPOCH 52:\tTraining loss:  12.096\tValidation loss:  7.840\n",
      "\n",
      "EPOCH 53:\tTraining loss:  11.773\tValidation loss:  7.472\n",
      "\n",
      "EPOCH 54:\tTraining loss:  11.845\tValidation loss:  7.862\n",
      "\n",
      "EPOCH 55:\tTraining loss:  11.457\tValidation loss:  7.321\n",
      "\n",
      "EPOCH 56:\tTraining loss:  11.670\tValidation loss:  7.430\n",
      "\n",
      "EPOCH 57:\tTraining loss:  11.553\tValidation loss:  7.481\n",
      "\n",
      "EPOCH 58:\tTraining loss:  11.594\tValidation loss:  7.897\n",
      "\n",
      "EPOCH 59:\tTraining loss:  12.085\tValidation loss:  7.629\n",
      "\n",
      "EPOCH 60:\tTraining loss:  11.710\tValidation loss:  7.460\n",
      "\n",
      "EPOCH 61:\tTraining loss:  12.078\tValidation loss:  7.530\n",
      "\n",
      "EPOCH 62:\tTraining loss:  11.629\tValidation loss:  7.594\n",
      "\n",
      "EPOCH 63:\tTraining loss:  12.005\tValidation loss:  7.869\n",
      "\n",
      "EPOCH 64:\tTraining loss:  11.939\tValidation loss:  7.463\n",
      "\n",
      "EPOCH 65:\tTraining loss:  11.560\tValidation loss:  7.415\n",
      "\n",
      "EPOCH 66:\tTraining loss:  12.677\tValidation loss:  7.450\n",
      "\n",
      "EPOCH 67:\tTraining loss:  11.604\tValidation loss:  7.840\n",
      "\n",
      "EPOCH 68:\tTraining loss:  11.714\tValidation loss:  7.645\n",
      "\n",
      "EPOCH 69:\tTraining loss:  12.523\tValidation loss:  7.480\n",
      "\n",
      "EPOCH 70:\tTraining loss:  11.516\tValidation loss:  7.874\n",
      "\n",
      "EPOCH 71:\tTraining loss:  11.515\tValidation loss:  7.707\n",
      "\n",
      "EPOCH 72:\tTraining loss:  11.492\tValidation loss:  7.298\n",
      "\n",
      "EPOCH 73:\tTraining loss:  12.163\tValidation loss:  7.632\n",
      "\n",
      "EPOCH 74:\tTraining loss:  11.871\tValidation loss:  7.513\n",
      "\n",
      "EPOCH 75:\tTraining loss:  11.618\tValidation loss:  7.649\n",
      "\n",
      "EPOCH 76:\tTraining loss:  11.565\tValidation loss:  7.651\n",
      "\n",
      "EPOCH 77:\tTraining loss:  11.699\tValidation loss:  7.827\n",
      "\n",
      "EPOCH 78:\tTraining loss:  11.517\tValidation loss:  7.607\n",
      "\n",
      "EPOCH 79:\tTraining loss:  11.996\tValidation loss:  7.664\n",
      "\n",
      "EPOCH 80:\tTraining loss:  11.921\tValidation loss:  7.433\n",
      "\n",
      "EPOCH 81:\tTraining loss:  11.396\tValidation loss:  7.465\n",
      "\n",
      "EPOCH 82:\tTraining loss:  12.379\tValidation loss:  7.406\n",
      "\n",
      "EPOCH 83:\tTraining loss:  12.527\tValidation loss:  7.708\n",
      "\n",
      "EPOCH 84:\tTraining loss:  12.072\tValidation loss:  7.759\n",
      "\n",
      "EPOCH 85:\tTraining loss:  11.966\tValidation loss:  7.441\n",
      "\n",
      "EPOCH 86:\tTraining loss:  11.985\tValidation loss:  7.839\n",
      "\n",
      "EPOCH 87:\tTraining loss:  12.262\tValidation loss:  7.439\n",
      "\n",
      "EPOCH 88:\tTraining loss:  11.689\tValidation loss:  7.752\n",
      "\n",
      "EPOCH 89:\tTraining loss:  11.530\tValidation loss:  7.506\n",
      "\n",
      "EPOCH 90:\tTraining loss:  11.655\tValidation loss:  7.667\n",
      "\n",
      "EPOCH 91:\tTraining loss:  11.798\tValidation loss:  7.798\n",
      "\n",
      "EPOCH 92:\tTraining loss:  12.275\tValidation loss:  7.606\n",
      "\n",
      "EPOCH 93:\tTraining loss:  12.443\tValidation loss:  7.474\n",
      "\n",
      "EPOCH 94:\tTraining loss:  12.019\tValidation loss:  7.350\n",
      "\n",
      "EPOCH 95:\tTraining loss:  12.046\tValidation loss:  7.702\n",
      "\n",
      "EPOCH 96:\tTraining loss:  11.843\tValidation loss:  7.349\n",
      "\n",
      "EPOCH 97:\tTraining loss:  11.573\tValidation loss:  7.435\n",
      "\n",
      "EPOCH 98:\tTraining loss:  11.768\tValidation loss:  7.548\n",
      "\n",
      "EPOCH 99:\tTraining loss:  11.805\tValidation loss:  7.884\n",
      "\n",
      "EPOCH 100:\tTraining loss:  11.866\tValidation loss:  7.555\n",
      "valuation on test set:\n",
      "R2: 0.7838835120201111\n"
     ]
    }
   ],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super().__init__()\n",
    "        self.output = nn.Linear(input_dims, output_dims)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.output(x).squeeze(1)\n",
    "\n",
    "model_lr = LinearRegression(input_dims, output_dims).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_lr.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "train_and_evaluate(model=model_lr, epochs=100, optimizer=optimizer, criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1:\tTraining loss:  154.702\tValidation loss:  57.432\n",
      "\n",
      "EPOCH 2:\tTraining loss:  45.598\tValidation loss:  39.028\n",
      "\n",
      "EPOCH 3:\tTraining loss:  35.270\tValidation loss:  25.857\n",
      "\n",
      "EPOCH 4:\tTraining loss:  26.740\tValidation loss:  18.978\n",
      "\n",
      "EPOCH 5:\tTraining loss:  20.906\tValidation loss:  15.328\n",
      "\n",
      "EPOCH 6:\tTraining loss:  18.542\tValidation loss:  9.103\n",
      "\n",
      "EPOCH 7:\tTraining loss:  16.811\tValidation loss:  8.437\n",
      "\n",
      "EPOCH 8:\tTraining loss:  16.611\tValidation loss:  8.375\n",
      "\n",
      "EPOCH 9:\tTraining loss:  14.083\tValidation loss:  7.835\n",
      "\n",
      "EPOCH 10:\tTraining loss:  13.490\tValidation loss:  8.019\n",
      "\n",
      "EPOCH 11:\tTraining loss:  13.739\tValidation loss:  7.358\n",
      "\n",
      "EPOCH 12:\tTraining loss:  13.011\tValidation loss:  9.474\n",
      "\n",
      "EPOCH 13:\tTraining loss:  12.695\tValidation loss:  7.588\n",
      "\n",
      "EPOCH 14:\tTraining loss:  12.196\tValidation loss:  7.079\n",
      "\n",
      "EPOCH 15:\tTraining loss:  12.015\tValidation loss:  7.032\n",
      "\n",
      "EPOCH 16:\tTraining loss:  11.812\tValidation loss:  6.951\n",
      "\n",
      "EPOCH 17:\tTraining loss:  11.515\tValidation loss:  6.790\n",
      "\n",
      "EPOCH 18:\tTraining loss:  11.343\tValidation loss:  7.534\n",
      "\n",
      "EPOCH 19:\tTraining loss:  10.610\tValidation loss:  7.003\n",
      "\n",
      "EPOCH 20:\tTraining loss:  11.142\tValidation loss:  6.613\n",
      "\n",
      "EPOCH 21:\tTraining loss:  10.727\tValidation loss:  6.717\n",
      "\n",
      "EPOCH 22:\tTraining loss:  10.761\tValidation loss:  6.524\n",
      "\n",
      "EPOCH 23:\tTraining loss:  10.127\tValidation loss:  6.161\n",
      "\n",
      "EPOCH 24:\tTraining loss:  9.936\tValidation loss:  7.970\n",
      "\n",
      "EPOCH 25:\tTraining loss:  11.511\tValidation loss:  7.856\n",
      "\n",
      "EPOCH 26:\tTraining loss:  10.048\tValidation loss:  6.433\n",
      "\n",
      "EPOCH 27:\tTraining loss:  9.513\tValidation loss:  5.689\n",
      "\n",
      "EPOCH 28:\tTraining loss:  9.410\tValidation loss:  5.612\n",
      "\n",
      "EPOCH 29:\tTraining loss:  10.217\tValidation loss:  5.663\n",
      "\n",
      "EPOCH 30:\tTraining loss:  9.960\tValidation loss:  5.819\n",
      "\n",
      "EPOCH 31:\tTraining loss:  9.544\tValidation loss:  5.816\n",
      "\n",
      "EPOCH 32:\tTraining loss:  10.528\tValidation loss:  5.733\n",
      "\n",
      "EPOCH 33:\tTraining loss:  9.309\tValidation loss:  7.827\n",
      "\n",
      "EPOCH 34:\tTraining loss:  9.109\tValidation loss:  5.998\n",
      "\n",
      "EPOCH 35:\tTraining loss:  9.453\tValidation loss:  5.716\n",
      "\n",
      "EPOCH 36:\tTraining loss:  8.899\tValidation loss:  5.361\n",
      "\n",
      "EPOCH 37:\tTraining loss:  10.148\tValidation loss:  6.287\n",
      "\n",
      "EPOCH 38:\tTraining loss:  8.893\tValidation loss:  5.570\n",
      "\n",
      "EPOCH 39:\tTraining loss:  9.202\tValidation loss:  5.551\n",
      "\n",
      "EPOCH 40:\tTraining loss:  8.853\tValidation loss:  5.629\n",
      "\n",
      "EPOCH 41:\tTraining loss:  8.601\tValidation loss:  5.215\n",
      "\n",
      "EPOCH 42:\tTraining loss:  9.952\tValidation loss:  5.310\n",
      "\n",
      "EPOCH 43:\tTraining loss:  8.738\tValidation loss:  6.081\n",
      "\n",
      "EPOCH 44:\tTraining loss:  8.843\tValidation loss:  5.351\n",
      "\n",
      "EPOCH 45:\tTraining loss:  9.267\tValidation loss:  7.414\n",
      "\n",
      "EPOCH 46:\tTraining loss:  8.621\tValidation loss:  5.308\n",
      "\n",
      "EPOCH 47:\tTraining loss:  8.789\tValidation loss:  7.967\n",
      "\n",
      "EPOCH 48:\tTraining loss:  8.433\tValidation loss:  7.678\n",
      "\n",
      "EPOCH 49:\tTraining loss:  8.626\tValidation loss:  5.502\n",
      "\n",
      "EPOCH 50:\tTraining loss:  8.429\tValidation loss:  4.885\n",
      "\n",
      "EPOCH 51:\tTraining loss:  8.452\tValidation loss:  5.032\n",
      "\n",
      "EPOCH 52:\tTraining loss:  8.190\tValidation loss:  5.544\n",
      "\n",
      "EPOCH 53:\tTraining loss:  8.441\tValidation loss:  5.239\n",
      "\n",
      "EPOCH 54:\tTraining loss:  9.039\tValidation loss:  7.880\n",
      "\n",
      "EPOCH 55:\tTraining loss:  8.417\tValidation loss:  4.842\n",
      "\n",
      "EPOCH 56:\tTraining loss:  8.509\tValidation loss:  7.642\n",
      "\n",
      "EPOCH 57:\tTraining loss:  8.823\tValidation loss:  4.747\n",
      "\n",
      "EPOCH 58:\tTraining loss:  8.472\tValidation loss:  4.850\n",
      "\n",
      "EPOCH 59:\tTraining loss:  8.441\tValidation loss:  5.904\n",
      "\n",
      "EPOCH 60:\tTraining loss:  8.144\tValidation loss:  4.698\n",
      "\n",
      "EPOCH 61:\tTraining loss:  8.128\tValidation loss:  5.408\n",
      "\n",
      "EPOCH 62:\tTraining loss:  8.755\tValidation loss:  5.031\n",
      "\n",
      "EPOCH 63:\tTraining loss:  8.462\tValidation loss:  5.381\n",
      "\n",
      "EPOCH 64:\tTraining loss:  8.214\tValidation loss:  4.769\n",
      "\n",
      "EPOCH 65:\tTraining loss:  8.332\tValidation loss:  7.626\n",
      "\n",
      "EPOCH 66:\tTraining loss:  9.216\tValidation loss:  4.716\n",
      "\n",
      "EPOCH 67:\tTraining loss:  8.617\tValidation loss:  5.017\n",
      "\n",
      "EPOCH 68:\tTraining loss:  8.133\tValidation loss:  4.952\n",
      "\n",
      "EPOCH 69:\tTraining loss:  8.225\tValidation loss:  5.683\n",
      "\n",
      "EPOCH 70:\tTraining loss:  8.466\tValidation loss:  5.387\n",
      "\n",
      "EPOCH 71:\tTraining loss:  8.711\tValidation loss:  4.669\n",
      "\n",
      "EPOCH 72:\tTraining loss:  9.326\tValidation loss:  4.830\n",
      "\n",
      "EPOCH 73:\tTraining loss:  8.238\tValidation loss:  4.855\n",
      "\n",
      "EPOCH 74:\tTraining loss:  8.517\tValidation loss:  6.024\n",
      "\n",
      "EPOCH 75:\tTraining loss:  8.664\tValidation loss:  4.767\n",
      "\n",
      "EPOCH 76:\tTraining loss:  8.227\tValidation loss:  4.892\n",
      "\n",
      "EPOCH 77:\tTraining loss:  8.398\tValidation loss:  5.603\n",
      "\n",
      "EPOCH 78:\tTraining loss:  8.813\tValidation loss:  4.748\n",
      "\n",
      "EPOCH 79:\tTraining loss:  8.361\tValidation loss:  5.178\n",
      "\n",
      "EPOCH 80:\tTraining loss:  8.064\tValidation loss:  5.313\n",
      "\n",
      "EPOCH 81:\tTraining loss:  8.141\tValidation loss:  5.056\n",
      "\n",
      "EPOCH 82:\tTraining loss:  7.963\tValidation loss:  4.635\n",
      "\n",
      "EPOCH 83:\tTraining loss:  8.086\tValidation loss:  5.081\n",
      "\n",
      "EPOCH 84:\tTraining loss:  8.043\tValidation loss:  5.772\n",
      "\n",
      "EPOCH 85:\tTraining loss:  8.270\tValidation loss:  5.565\n",
      "\n",
      "EPOCH 86:\tTraining loss:  9.329\tValidation loss:  6.911\n",
      "\n",
      "EPOCH 87:\tTraining loss:  9.191\tValidation loss:  4.873\n",
      "\n",
      "EPOCH 88:\tTraining loss:  8.881\tValidation loss:  5.132\n",
      "\n",
      "EPOCH 89:\tTraining loss:  7.810\tValidation loss:  5.730\n",
      "\n",
      "EPOCH 90:\tTraining loss:  8.750\tValidation loss:  5.235\n",
      "\n",
      "EPOCH 91:\tTraining loss:  8.274\tValidation loss:  5.097\n",
      "\n",
      "EPOCH 92:\tTraining loss:  7.568\tValidation loss:  4.680\n",
      "\n",
      "EPOCH 93:\tTraining loss:  8.052\tValidation loss:  4.804\n",
      "\n",
      "EPOCH 94:\tTraining loss:  8.282\tValidation loss:  5.393\n",
      "\n",
      "EPOCH 95:\tTraining loss:  8.076\tValidation loss:  5.212\n",
      "\n",
      "EPOCH 96:\tTraining loss:  7.782\tValidation loss:  4.893\n",
      "\n",
      "EPOCH 97:\tTraining loss:  8.487\tValidation loss:  4.946\n",
      "\n",
      "EPOCH 98:\tTraining loss:  8.747\tValidation loss:  5.486\n",
      "\n",
      "EPOCH 99:\tTraining loss:  8.270\tValidation loss:  4.826\n",
      "\n",
      "EPOCH 100:\tTraining loss:  9.569\tValidation loss:  7.459\n",
      "valuation on test set:\n",
      "R2: 0.825605034828186\n"
     ]
    }
   ],
   "source": [
    "mlp_sigmoid = MLP(input_dims=input_dims, hidden_dims=hidden_dims, output_dims=output_dims, activation='sigmoid').to(device)\n",
    "optimizer = torch.optim.SGD(mlp_sigmoid.parameters(), lr = 0.01)\n",
    "criterion = nn.MSELoss()\n",
    "train_and_evaluate(mlp_sigmoid, epochs=100, optimizer=optimizer, criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1:\tTraining loss:  270.298\tValidation loss:  23.794\n",
      "\n",
      "EPOCH 2:\tTraining loss:  23.296\tValidation loss:  10.683\n",
      "\n",
      "EPOCH 3:\tTraining loss:  17.826\tValidation loss:  11.399\n",
      "\n",
      "EPOCH 4:\tTraining loss:  14.688\tValidation loss:  9.336\n",
      "\n",
      "EPOCH 5:\tTraining loss:  13.677\tValidation loss:  7.972\n",
      "\n",
      "EPOCH 6:\tTraining loss:  11.327\tValidation loss:  7.513\n",
      "\n",
      "EPOCH 7:\tTraining loss:  10.812\tValidation loss:  7.302\n",
      "\n",
      "EPOCH 8:\tTraining loss:  10.686\tValidation loss:  6.366\n",
      "\n",
      "EPOCH 9:\tTraining loss:  10.625\tValidation loss:  5.676\n",
      "\n",
      "EPOCH 10:\tTraining loss:  8.697\tValidation loss:  6.100\n",
      "\n",
      "EPOCH 11:\tTraining loss:  8.753\tValidation loss:  6.475\n",
      "\n",
      "EPOCH 12:\tTraining loss:  8.831\tValidation loss:  8.572\n",
      "\n",
      "EPOCH 13:\tTraining loss:  8.494\tValidation loss:  5.058\n",
      "\n",
      "EPOCH 14:\tTraining loss:  8.621\tValidation loss:  5.805\n",
      "\n",
      "EPOCH 15:\tTraining loss:  7.231\tValidation loss:  6.339\n",
      "\n",
      "EPOCH 16:\tTraining loss:  7.649\tValidation loss:  4.847\n",
      "\n",
      "EPOCH 17:\tTraining loss:  8.105\tValidation loss:  7.179\n",
      "\n",
      "EPOCH 18:\tTraining loss:  8.516\tValidation loss:  6.316\n",
      "\n",
      "EPOCH 19:\tTraining loss:  8.108\tValidation loss:  6.261\n",
      "\n",
      "EPOCH 20:\tTraining loss:  7.567\tValidation loss:  8.230\n",
      "\n",
      "EPOCH 21:\tTraining loss:  7.477\tValidation loss:  5.339\n",
      "\n",
      "EPOCH 22:\tTraining loss:  7.979\tValidation loss:  6.062\n",
      "\n",
      "EPOCH 23:\tTraining loss:  7.591\tValidation loss:  8.450\n",
      "\n",
      "EPOCH 24:\tTraining loss:  7.953\tValidation loss:  9.464\n",
      "\n",
      "EPOCH 25:\tTraining loss:  7.632\tValidation loss:  7.367\n",
      "\n",
      "EPOCH 26:\tTraining loss:  8.034\tValidation loss:  8.302\n",
      "\n",
      "EPOCH 27:\tTraining loss:  6.909\tValidation loss:  5.215\n",
      "\n",
      "EPOCH 28:\tTraining loss:  7.365\tValidation loss:  6.054\n",
      "\n",
      "EPOCH 29:\tTraining loss:  7.017\tValidation loss:  5.423\n",
      "\n",
      "EPOCH 30:\tTraining loss:  7.197\tValidation loss:  8.958\n",
      "\n",
      "EPOCH 31:\tTraining loss:  7.297\tValidation loss:  5.751\n",
      "\n",
      "EPOCH 32:\tTraining loss:  6.739\tValidation loss:  6.212\n",
      "\n",
      "EPOCH 33:\tTraining loss:  6.417\tValidation loss:  5.604\n",
      "\n",
      "EPOCH 34:\tTraining loss:  6.542\tValidation loss:  6.024\n",
      "\n",
      "EPOCH 35:\tTraining loss:  6.786\tValidation loss:  11.616\n",
      "\n",
      "EPOCH 36:\tTraining loss:  7.274\tValidation loss:  5.028\n",
      "\n",
      "EPOCH 37:\tTraining loss:  6.543\tValidation loss:  5.022\n",
      "\n",
      "EPOCH 38:\tTraining loss:  7.103\tValidation loss:  5.699\n",
      "\n",
      "EPOCH 39:\tTraining loss:  6.731\tValidation loss:  6.713\n",
      "\n",
      "EPOCH 40:\tTraining loss:  8.163\tValidation loss:  6.076\n",
      "\n",
      "EPOCH 41:\tTraining loss:  6.720\tValidation loss:  5.557\n",
      "\n",
      "EPOCH 42:\tTraining loss:  6.651\tValidation loss:  7.653\n",
      "\n",
      "EPOCH 43:\tTraining loss:  6.010\tValidation loss:  4.999\n",
      "\n",
      "EPOCH 44:\tTraining loss:  6.237\tValidation loss:  6.733\n",
      "\n",
      "EPOCH 45:\tTraining loss:  6.632\tValidation loss:  7.688\n",
      "\n",
      "EPOCH 46:\tTraining loss:  6.972\tValidation loss:  7.584\n",
      "\n",
      "EPOCH 47:\tTraining loss:  6.493\tValidation loss:  5.145\n",
      "\n",
      "EPOCH 48:\tTraining loss:  6.778\tValidation loss:  4.918\n",
      "\n",
      "EPOCH 49:\tTraining loss:  5.929\tValidation loss:  5.605\n",
      "\n",
      "EPOCH 50:\tTraining loss:  5.991\tValidation loss:  5.479\n",
      "\n",
      "EPOCH 51:\tTraining loss:  7.412\tValidation loss:  9.003\n",
      "\n",
      "EPOCH 52:\tTraining loss:  6.643\tValidation loss:  5.818\n",
      "\n",
      "EPOCH 53:\tTraining loss:  5.714\tValidation loss:  4.913\n",
      "\n",
      "EPOCH 54:\tTraining loss:  5.955\tValidation loss:  5.010\n",
      "\n",
      "EPOCH 55:\tTraining loss:  6.151\tValidation loss:  5.277\n",
      "\n",
      "EPOCH 56:\tTraining loss:  5.916\tValidation loss:  4.850\n",
      "\n",
      "EPOCH 57:\tTraining loss:  5.901\tValidation loss:  4.544\n",
      "\n",
      "EPOCH 58:\tTraining loss:  6.260\tValidation loss:  5.286\n",
      "\n",
      "EPOCH 59:\tTraining loss:  6.362\tValidation loss:  5.108\n",
      "\n",
      "EPOCH 60:\tTraining loss:  5.865\tValidation loss:  6.919\n",
      "\n",
      "EPOCH 61:\tTraining loss:  5.748\tValidation loss:  5.586\n",
      "\n",
      "EPOCH 62:\tTraining loss:  6.175\tValidation loss:  5.255\n",
      "\n",
      "EPOCH 63:\tTraining loss:  5.923\tValidation loss:  5.422\n",
      "\n",
      "EPOCH 64:\tTraining loss:  5.441\tValidation loss:  4.565\n",
      "\n",
      "EPOCH 65:\tTraining loss:  5.302\tValidation loss:  4.784\n",
      "\n",
      "EPOCH 66:\tTraining loss:  6.071\tValidation loss:  5.129\n",
      "\n",
      "EPOCH 67:\tTraining loss:  6.463\tValidation loss:  5.043\n",
      "\n",
      "EPOCH 68:\tTraining loss:  6.019\tValidation loss:  5.083\n",
      "\n",
      "EPOCH 69:\tTraining loss:  6.406\tValidation loss:  6.275\n",
      "\n",
      "EPOCH 70:\tTraining loss:  5.554\tValidation loss:  5.256\n",
      "\n",
      "EPOCH 71:\tTraining loss:  5.516\tValidation loss:  4.890\n",
      "\n",
      "EPOCH 72:\tTraining loss:  5.418\tValidation loss:  5.243\n",
      "\n",
      "EPOCH 73:\tTraining loss:  5.132\tValidation loss:  5.033\n",
      "\n",
      "EPOCH 74:\tTraining loss:  6.061\tValidation loss:  7.430\n",
      "\n",
      "EPOCH 75:\tTraining loss:  6.138\tValidation loss:  9.577\n",
      "\n",
      "EPOCH 76:\tTraining loss:  5.744\tValidation loss:  5.093\n",
      "\n",
      "EPOCH 77:\tTraining loss:  5.625\tValidation loss:  5.629\n",
      "\n",
      "EPOCH 78:\tTraining loss:  5.734\tValidation loss:  5.950\n",
      "\n",
      "EPOCH 79:\tTraining loss:  5.681\tValidation loss:  5.707\n",
      "\n",
      "EPOCH 80:\tTraining loss:  5.587\tValidation loss:  7.035\n",
      "\n",
      "EPOCH 81:\tTraining loss:  5.437\tValidation loss:  5.598\n",
      "\n",
      "EPOCH 82:\tTraining loss:  5.718\tValidation loss:  8.603\n",
      "\n",
      "EPOCH 83:\tTraining loss:  5.336\tValidation loss:  5.218\n",
      "\n",
      "EPOCH 84:\tTraining loss:  5.071\tValidation loss:  5.259\n",
      "\n",
      "EPOCH 85:\tTraining loss:  5.845\tValidation loss:  7.973\n",
      "\n",
      "EPOCH 86:\tTraining loss:  5.588\tValidation loss:  6.026\n",
      "\n",
      "EPOCH 87:\tTraining loss:  4.975\tValidation loss:  5.281\n",
      "\n",
      "EPOCH 88:\tTraining loss:  5.042\tValidation loss:  4.912\n",
      "\n",
      "EPOCH 89:\tTraining loss:  4.878\tValidation loss:  4.844\n",
      "\n",
      "EPOCH 90:\tTraining loss:  4.979\tValidation loss:  5.002\n",
      "\n",
      "EPOCH 91:\tTraining loss:  5.653\tValidation loss:  7.148\n",
      "\n",
      "EPOCH 92:\tTraining loss:  5.035\tValidation loss:  5.880\n",
      "\n",
      "EPOCH 93:\tTraining loss:  5.228\tValidation loss:  6.190\n",
      "\n",
      "EPOCH 94:\tTraining loss:  5.221\tValidation loss:  5.821\n",
      "\n",
      "EPOCH 95:\tTraining loss:  4.782\tValidation loss:  5.541\n",
      "\n",
      "EPOCH 96:\tTraining loss:  5.133\tValidation loss:  6.273\n",
      "\n",
      "EPOCH 97:\tTraining loss:  4.685\tValidation loss:  5.928\n",
      "\n",
      "EPOCH 98:\tTraining loss:  4.653\tValidation loss:  5.704\n",
      "\n",
      "EPOCH 99:\tTraining loss:  5.259\tValidation loss:  7.243\n",
      "\n",
      "EPOCH 100:\tTraining loss:  5.035\tValidation loss:  5.499\n",
      "valuation on test set:\n",
      "R2: 0.9134730696678162\n"
     ]
    }
   ],
   "source": [
    "mlp_tanh = MLP(input_dims=input_dims, hidden_dims=hidden_dims, output_dims=output_dims, activation='tanh').to(device)\n",
    "optimizer = torch.optim.SGD(mlp_tanh.parameters(), lr = 0.01)\n",
    "criterion = nn.MSELoss()\n",
    "train_and_evaluate(mlp_tanh, epochs=100, optimizer=optimizer, criterion=criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio_exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
