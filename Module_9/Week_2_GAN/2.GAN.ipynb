{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from utils and gan_models\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "\n",
    "import utils\n",
    "from gan_models import Generator, Discriminator\n",
    "\n",
    "# Get device from utils\n",
    "device = utils.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset parameters\n",
    "img_size = 32\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Get dataloader using utils function\n",
    "dataloader = utils.get_mnist_dataloader(img_size=img_size, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "channels = 1\n",
    "img_shape = (channels, img_size, img_size)\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim=latent_dim, img_shape=img_shape)\n",
    "discriminator = Discriminator(img_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.to(device)\n",
    "discriminator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory using utils function\n",
    "output_dir = \"./images_gan\"\n",
    "utils.create_dir(output_dir)\n",
    "save_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0001)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "hist = {\n",
    "    \"train_G_loss\": [],\n",
    "    \"train_D_loss\": [],\n",
    "}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_G_loss = 0.0\n",
    "    running_D_loss = 0.0\n",
    "\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        real_imgs = imgs.to(device)\n",
    "        real_labels = torch.ones(imgs.shape[0], 1).to(device)\n",
    "        fake_labels = torch.zeros(imgs.shape[0], 1).to(device)\n",
    "\n",
    "        # -------------------------- Train Generator --- \n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Noise input for Generator\n",
    "        z = torch.randn((imgs.shape[0], latent_dim)).to(device)\n",
    "\n",
    "        gen_imgs = generator(z)\n",
    "        G_loss = criterion(discriminator(gen_imgs), real_labels)\n",
    "        running_G_loss += G_loss.item()\n",
    "\n",
    "        G_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "\n",
    "        # -------------- Train Discriminator --- \n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = criterion(discriminator(real_imgs), real_labels)\n",
    "        fake_loss = criterion(discriminator(gen_imgs.detach()), fake_labels) # .detach() to prevent back prop to Generator\n",
    "        D_loss = (real_loss + fake_loss) / 2\n",
    "        running_D_loss += D_loss.item()\n",
    "\n",
    "        D_loss.backward()\n",
    "        optimizer_D.step()\n",
    "    \n",
    "    epoch_G_loss = running_G_loss / len(dataloader)\n",
    "    epoch_D_loss = running_D_loss / len(dataloader)\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Train G Loss: {epoch_G_loss:.4f}, Train D Loss: {epoch_D_loss:.4f}\")\n",
    "\n",
    "    hist[\"train_G_loss\"].append(epoch_G_loss)\n",
    "    hist[\"train_D_loss\"].append(epoch_D_loss)\n",
    "\n",
    "    if epoch % save_interval == 0:\n",
    "        save_image(gen_imgs.data[:25], f\"images/epoch_{epoch}.png\", nrow=5, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio_exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
